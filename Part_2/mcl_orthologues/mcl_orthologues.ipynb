{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Processing MCL Output - mcl_orthologues.ipynb\n",
      "\n",
      "# Overview\n",
      "\n",
      "This iPython notebook describes the process of parsing MCL output, and generating a corresponding ACT-friendly .crunch format file for visualisation.\n",
      "\n",
      "Parsing software output files is still an unfortunately large part of bioinformatics, and this activity is intended to lead you through the processes of\n",
      "\n",
      "1. parsing MCL output in Python\n",
      "2. parsing GenBank files with Biopython\n",
      "3. relating sequence identifiers/accession numbers across datasets\n",
      "4. writing a new output file combining information from both sources, in a different format"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 1. Reading MCL output\n",
      "\n",
      "The MCL output we want to read is the cluster file `out.seq.mci.I60`. It is a plain text file with a format of one line per cluster. Each member of the cluster is identified with its FASTA sequence ID, and members are separated with the tab character, e.g.\n",
      "\n",
      "```\n",
      "gi|188535157|ref|YP_001908954.1|\tgi|261820293|ref|YP_003258399.1|\tgi|50119794|ref|YP_048961.1|\tgi|261821088|ref|YP_003259194.1|\n",
      "gi|188535466|ref|YP_001909263.1|\tgi|50119041|ref|YP_048208.1|\tgi|261823647|ref|YP_003261753.1|\n",
      "```\n",
      "\n",
      "Therefore we wish to read the data into a suitable data structure (e.g. a list of tuples), in order to summarise and process the data. We can do this with the function `read_mcl()` below."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Function to split a full sequence reference ID into only the last value\n",
      "def split_seqid(seqid):\n",
      "    return seqid.split('|')[-2]\n",
      "\n",
      "# Function to read MCL cluster output into a list of tuples. Each tuple\n",
      "# contains all members of a single MCL cluster\n",
      "def read_mcl(filename):\n",
      "    \"\"\" Returns a list of tuples, where each tuple contains all the \n",
      "        sequence identifiers for a single cluster, described in an\n",
      "        MCL cluster output file\n",
      "        \n",
      "        - filename, the MCL cluster output file\n",
      "    \"\"\"\n",
      "    clusters = []  # The list of clusters\n",
      "    with open(filename, 'rU') as fh:\n",
      "        for line in [l.strip().split() for l in fh if len(l.strip())]:\n",
      "            clusters.append(tuple([split_seqid(l) for l in line]))\n",
      "    return clusters"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can quickly get a summary of the cluster data, and use iPython's graphing capabilities to visualise the results."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_clusters = read_mcl(\"data/out.seq.mci.I60\")\n",
      "len(all_clusters)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Not all clusters represent putative orthologues, some only have one member (i.e. are singletons). We remove these:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clusters = [c for c in all_clusters if len(c) > 1]\n",
      "len(clusters)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That's quite a reduction in the number of clusters. What is the distribution of cluster sizes? We can find out with a histogram:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cluster_lens = [len(c) for c in clusters]\n",
      "h = hist(cluster_lens, bins=max(cluster_lens))\n",
      "xlabel(\"cluster_size\")\n",
      "ylabel(\"frequency\")\n",
      "t = title(\"Cluster size frequency\")\n",
      "limits = axis([1, 10, 0, 1.1 * max(h[0])])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Since we have three organisms being compared, we might interpret the peak at a cluster size of three to represent sequences that are equivalent across all three isolates. Those in the bar representing a cluster size of two might contain mostly sequences present in two of the three organisms, but not the third.\n",
      "\n",
      "However, the sequence IDs used to construct the clusters do not contain information about the sequence's originating organism, so we need to import this data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 2. Loading GenBank data\n",
      "\n",
      "We obtain the annotation data for our three organisms from NCBI - the files have already been downloaded in GenBank (`.gbk`) format for you, in the `data` subdirectory. Unlike **MCL** output, the `.gbk` format is standardised, complex, and common enough to be used ubiquitously, so there is a parser in the Biopython programming libraries. We use this to load our data, below.\n",
      "\n",
      "However, we do not want to keep all the data in each GenBank file - what we really want are the originating organism, and the start and end locations for each clustered CDS relative to that organism's chromosome. So we use a function that extracts this information: `read_genbank()`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# IMPORTS\n",
      "from Bio import SeqIO\n",
      "\n",
      "# Function to process GenBank files into a dictionary of CDS features,\n",
      "# keyed by protein ID, where the values are a tuple of (source, start, end, \n",
      "# strand) information.\n",
      "def read_genbank(*filenames):\n",
      "    \"\"\" Returns a dictionary of CDS annotations, where the dictionary keys\n",
      "        are the CDS protein ID accession numbers, and the values are\n",
      "        (source, start, end, strand, id) information about the CDS location\n",
      "        on the chromosome.\n",
      "        \n",
      "        - *filenames, the organism's GenBank annotation files\n",
      "    \"\"\"\n",
      "    ft_dict = {}\n",
      "    for filename in filenames:\n",
      "        with open(filename, 'rU') as fh:\n",
      "            record = SeqIO.read(fh, 'genbank')\n",
      "            # Reconstruct the name in the corresponding .fna file\n",
      "            record_name = '|'.join([\"gi\", record.annotations['gi'],\n",
      "                                    \"ref\", record.id])\n",
      "            for ft in [f for f in record.features if f.type == \"CDS\"]:\n",
      "                ft_dict[ft.qualifiers['protein_id'][0]] = \\\n",
      "                    (record_name, int(ft.location.start), \n",
      "                     int(ft.location.end), ft.location.strand)\n",
      "    print \"Loaded %d features\" % len(ft_dict)\n",
      "    return ft_dict\n",
      "                "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This function takes a list of GenBank files, and gives us back a list of CDS feature locations whose identifiers should match up to those in the MCL data we read in above. We load in the data by running the cell below:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features = read_genbank(\"data/NC_004547.gbk\", \"data/NC_010694.gbk\", \n",
      "                        \"data/NC_013421.gbk\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 3. Relate the cluster data to the GenBank data, and write `.crunch` output\n",
      "\n",
      "Now we can create a new set of `.crunch` format files for viewing in **ACT**, that represents the cluster matches we found with **MCL**, that will work with the sequence and annotation data in our GenBank files.\n",
      "\n",
      "The function below will generate these files for us. However, we do not have score, or percentage identity information: the MCL output file gives us cluster membership only, not edge weights. We could parse this information from the BLAST input used for clustering, but for this exercise, we simply set all values to 100%."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# IMPORTS\n",
      "import os\n",
      "import itertools\n",
      "from collections import defaultdict\n",
      "\n",
      "# Function to split a full sequence reference ID into only the last value\n",
      "def split_seqid(seqid):\n",
      "    return seqid.split('|')[-1].split('.')[0]\n",
      "\n",
      "# Function to create a .crunch file from our cluster and annotation data\n",
      "def write_crunch(clusters, features, outdir=\"data\"):\n",
      "    \"\"\" Writes a .crunch format file describing our MCL output clusters.\n",
      "        Match scores and percentage identities are set arbitrarily to 100%.\n",
      "        \n",
      "        - clusters, list of tuples produced by read_mcl\n",
      "        - features, dictonary produced by read_genbank\n",
      "        - outdir, directory in which to place output .crunch format files\n",
      "    \"\"\"\n",
      "    # Loop over clusters, and store each pairwise combination in a \n",
      "    # suitable set\n",
      "    pairs_dict = defaultdict(set)\n",
      "    for cluster in clusters:\n",
      "        pairs = itertools.combinations(cluster, 2)\n",
      "        for pair in pairs:\n",
      "            # Using sorted in this way ensures that each organism pair \n",
      "            # will be counted only once\n",
      "            ft1, ft2 = sorted([features[pair[0]], features[pair[1]]])\n",
      "            source1, source2 = split_seqid(ft1[0]), split_seqid(ft2[0])\n",
      "            key = \"%s_vs_%s\" % (source1, source2)\n",
      "            pairs_dict[key].add((ft1, ft2))\n",
      "    # Report the number of entries in each grouping/comparison,\n",
      "    #\u00a0and write files\n",
      "    for k, v in pairs_dict.items():\n",
      "        print \"Comparison: %s, Matches: %d\" % (k, len(v))\n",
      "        with open(os.path.join(outdir, \"%s.crunch\" % k), 'w') as fh:\n",
      "            for ft1, ft2 in v:\n",
      "                fh.write(\" \".join([\"100\", \"100\",\n",
      "                                    str(ft1[2]) if ft1[3] < 0 else str(ft1[1]),\n",
      "                                    str(ft1[1]) if ft1[3] < 0 else str(ft1[2]),                                \n",
      "                                    str(ft1[0]),\n",
      "                                    str(ft2[2]) if ft2[3] < 0 else str(ft2[1]),\n",
      "                                    str(ft2[1]) if ft2[3] < 0 else str(ft2[2]),\n",
      "                                    str(ft2[0])]                                \n",
      "                                    ) + \"\\n\")\n",
      "    \n",
      "            \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We use this function to write suitable **ACT** friendly output, below."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "write_crunch(clusters, features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `.crunch` files have been written to the `data` directory (by default), and are now available for visualisation using **ACT**, so you can return to the `mcl_orthologues` `README.md` Markdown file, and continue the activity there."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}